{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, sequence_length, start_token, batch_size, device='cpu'):\n",
    "\n",
    "        np.random.seed(66)\n",
    "        torch.manual_seed(66)\n",
    "        \n",
    "        super(TargetLSTM, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        self.start_token = start_token\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        \n",
    "        # Define layers\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "        for param in self.parameters():\n",
    "            nn.init.normal_(param, mean=0.0, std=0.1)\n",
    "        \n",
    "        # Initialize on device\n",
    "        self.to(device)\n",
    "    \n",
    "    def load_pytorch_dict_params(self, params_path):\n",
    "        \"\"\"\n",
    "        Load parameters from a PyTorch dictionary format\n",
    "        \"\"\"\n",
    "        with open(params_path, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Load embedding weights\n",
    "            self.embeddings.weight.copy_(params['emb'])\n",
    "            \n",
    "            # Load output layer weights\n",
    "            self.output_layer.weight.copy_(params['out_w'])\n",
    "            self.output_layer.bias.copy_(params['out_b'])\n",
    "            \n",
    "            # Load LSTM weights\n",
    "            lstm_dict = params['lstm']\n",
    "            self.lstm.weight_ih_l0.copy_(lstm_dict['weight_ih_l0'])\n",
    "            self.lstm.weight_hh_l0.copy_(lstm_dict['weight_hh_l0'])\n",
    "            self.lstm.bias_ih_l0.copy_(lstm_dict['bias_ih_l0'])\n",
    "            self.lstm.bias_hh_l0.copy_(lstm_dict['bias_hh_l0'])\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "\n",
    "        emb = self.embeddings(x)                    # [batch_size, sequence_length, embedding_dim]\n",
    "        lstm_out, hidden = self.lstm(emb, hidden)   # lstm_out: [batch_size, sequence_length, hidden_dim]\n",
    "        logits = self.output_layer(lstm_out)        # [batch_size, sequence_length, vocab_size]\n",
    "        \n",
    "        return logits, hidden\n",
    "    \n",
    "    def generate(self, num_samples):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Start token for all sequences\n",
    "            x = torch.full((num_samples, 1), self.start_token, dtype=torch.long, device=self.device)\n",
    "            hidden = None  # Let PyTorch initialize the hidden state\n",
    "\n",
    "            generated_sequences = torch.zeros(num_samples, self.sequence_length, dtype=torch.long, device=self.device)\n",
    "\n",
    "            for i in range(self.sequence_length):\n",
    "                # Forward pass\n",
    "                emb = self.embeddings(x[:, -1:])  # Only use the last token\n",
    "                lstm_out, hidden = self.lstm(emb, hidden)\n",
    "                logits = self.output_layer(lstm_out)\n",
    "                \n",
    "                # Sample from distribution\n",
    "                probs = F.softmax(logits.squeeze(1), dim=-1)\n",
    "                next_token = torch.multinomial(probs, 1)\n",
    "                \n",
    "                # Add to sequence\n",
    "                generated_sequences[:, i] = next_token.squeeze()\n",
    "                \n",
    "                # Update input for next step (only need the current token, not the entire history)\n",
    "                x = next_token\n",
    "            \n",
    "            return generated_sequences\n",
    "            \n",
    "    def calculate_nll(self, generated_sequences):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Use all tokens except the last one as input\n",
    "            inputs = generated_sequences[:, :-1]\n",
    "            \n",
    "            # Use all tokens except the first one as targets\n",
    "            targets = generated_sequences[:, 1:]\n",
    "            \n",
    "            # Forward pass\n",
    "            logits, _ = self.forward(inputs)\n",
    "            \n",
    "            # Calculate negative log-likelihood\n",
    "            nll = F.cross_entropy(logits.reshape(-1, self.vocab_size), targets.reshape(-1), reduction='mean')\n",
    "            \n",
    "            return nll.item()\n",
    "\n",
    "    def calculate_nll_exact(self, generated_sequences):\n",
    "        \"\"\"\n",
    "        Calculate negative log-likelihood in a way that exactly matches the TensorFlow implementation\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Use all tokens except the last one as input\n",
    "            inputs = generated_sequences[:, :-1]\n",
    "            \n",
    "            # Forward pass\n",
    "            logits, _ = self.forward(inputs)\n",
    "            \n",
    "            # Convert logits to probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            # Use all tokens except the first one as targets\n",
    "            targets = generated_sequences[:, 1:]\n",
    "            \n",
    "            # One-hot encode targets\n",
    "            targets_one_hot = F.one_hot(targets, num_classes=self.vocab_size).float()\n",
    "            \n",
    "            # Calculate negative log-likelihood exactly like in TensorFlow\n",
    "            log_probs = torch.log(torch.clamp(probs, min=1e-20))\n",
    "            nll = -torch.sum(\n",
    "                targets_one_hot.reshape(-1, self.vocab_size) * \n",
    "                log_probs.reshape(-1, self.vocab_size)\n",
    "            ) / (self.sequence_length * self.batch_size)\n",
    "            \n",
    "            return nll.item()\n",
    "\n",
    "    def save_params(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "        \n",
    "    def load_params(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "        \n",
    "    def save_samples(self, samples, file_path):\n",
    "        with open(file_path, 'w') as f:\n",
    "            for sample in samples.cpu().numpy():\n",
    "                f.write(' '.join([str(int(x)) for x in sample]) + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, sequence_length, start_token, batch_size, device='cpu'):\n",
    "\n",
    "        np.random.seed(66)\n",
    "        torch.manual_seed(66)\n",
    "        \n",
    "        super(TestLSTM, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        self.start_token = start_token\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        \n",
    "        # Define layers\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "        for param in self.parameters():\n",
    "            nn.init.normal_(param, mean=100.0, std=3.1)\n",
    "        \n",
    "        # Initialize on device\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "\n",
    "        emb = self.embeddings(x)                    # [batch_size, sequence_length, embedding_dim]\n",
    "        lstm_out, hidden = self.lstm(emb, hidden)   # lstm_out: [batch_size, sequence_length, hidden_dim]\n",
    "        logits = self.output_layer(lstm_out)        # [batch_size, sequence_length, vocab_size]\n",
    "        \n",
    "        return logits, hidden\n",
    "    \n",
    "    def generate(self, num_samples):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Start token for all sequences\n",
    "            x = torch.full((num_samples, 1), self.start_token, dtype=torch.long, device=self.device)\n",
    "            hidden = None  # Let PyTorch initialize the hidden state\n",
    "\n",
    "            generated_sequences = torch.zeros(num_samples, self.sequence_length, dtype=torch.long, device=self.device)\n",
    "\n",
    "            for i in range(self.sequence_length):\n",
    "                # Forward pass\n",
    "                emb = self.embeddings(x[:, -1:])  # Only use the last token\n",
    "                lstm_out, hidden = self.lstm(emb, hidden)\n",
    "                logits = self.output_layer(lstm_out)\n",
    "                \n",
    "                # Sample from distribution\n",
    "                probs = F.softmax(logits.squeeze(1), dim=-1)\n",
    "                next_token = torch.multinomial(probs, 1)\n",
    "                \n",
    "                # Add to sequence\n",
    "                generated_sequences[:, i] = next_token.squeeze()\n",
    "                \n",
    "                # Update input for next step (only need the current token, not the entire history)\n",
    "                x = next_token\n",
    "            \n",
    "            return generated_sequences\n",
    "            \n",
    "    def calculate_nll(self, generated_sequences):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Use all tokens except the last one as input\n",
    "            inputs = generated_sequences[:, :-1]\n",
    "            \n",
    "            # Use all tokens except the first one as targets\n",
    "            targets = generated_sequences[:, 1:]\n",
    "            \n",
    "            # Forward pass\n",
    "            logits, _ = self.forward(inputs)\n",
    "            \n",
    "            # Calculate negative log-likelihood\n",
    "            nll = F.cross_entropy(logits.reshape(-1, self.vocab_size), targets.reshape(-1), reduction='mean')\n",
    "            \n",
    "            return nll.item()\n",
    "\n",
    "    def calculate_nll_exact(self, generated_sequences):\n",
    "        \"\"\"\n",
    "        Calculate negative log-likelihood in a way that exactly matches the TensorFlow implementation\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Use all tokens except the last one as input\n",
    "            inputs = generated_sequences[:, :-1]\n",
    "            \n",
    "            # Forward pass\n",
    "            logits, _ = self.forward(inputs)\n",
    "            \n",
    "            # Convert logits to probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            # Use all tokens except the first one as targets\n",
    "            targets = generated_sequences[:, 1:]\n",
    "            \n",
    "            # One-hot encode targets\n",
    "            targets_one_hot = F.one_hot(targets, num_classes=self.vocab_size).float()\n",
    "            \n",
    "            # Calculate negative log-likelihood exactly like in TensorFlow\n",
    "            log_probs = torch.log(torch.clamp(probs, min=1e-20))\n",
    "            nll = -torch.sum(\n",
    "                targets_one_hot.reshape(-1, self.vocab_size) * \n",
    "                log_probs.reshape(-1, self.vocab_size)\n",
    "            ) / (self.sequence_length * self.batch_size)\n",
    "            \n",
    "            return nll.item()\n",
    "\n",
    "    def save_params(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "        \n",
    "    def load_params(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "        \n",
    "    def save_samples(self, samples, file_path):\n",
    "        with open(file_path, 'w') as f:\n",
    "            for sample in samples.cpu().numpy():\n",
    "                f.write(' '.join([str(int(x)) for x in sample]) + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters (matching the original implementation)\n",
    "vocab_size = 5000\n",
    "embedding_dim = 32\n",
    "hidden_dim = 32\n",
    "sequence_length = 20\n",
    "start_token = 0\n",
    "batch_size = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "oracle = TargetLSTM(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    sequence_length=sequence_length,\n",
    "    start_token=start_token,\n",
    "    batch_size=batch_size,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "test_case = TestLSTM(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    sequence_length=sequence_length,\n",
    "    start_token=start_token,\n",
    "    batch_size=batch_size,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "oracle_sequences = oracle.generate(num_samples)\n",
    "test_sequences = test_case.generate(num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(oracle_sequences.flatten(), density=False)\n",
    "plt.hist(test_sequences.flatten(), density=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NLL of oracle-generated sequences: 8.511882781982422\n",
      "\n",
      "NLL of oracle-test sequences: 8.497983932495117\n"
     ]
    }
   ],
   "source": [
    "oracle_nll = oracle.calculate_nll(oracle_sequences)\n",
    "print(f\"\\nNLL of oracle-generated sequences: {oracle_nll}\")\n",
    "\n",
    "oracle_nll = oracle.calculate_nll(test_sequences)\n",
    "print(f\"\\nNLL of oracle-test sequences: {oracle_nll}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NLL of oracle-test sequences: 0.024663729593157768\n",
      "\n",
      "NLL of oracle-generated sequences: 63.696434020996094\n"
     ]
    }
   ],
   "source": [
    "oracle_nll = test_case.calculate_nll(test_sequences)\n",
    "print(f\"\\nNLL of oracle-test sequences: {oracle_nll}\")\n",
    "\n",
    "oracle_nll = test_case.calculate_nll(oracle_sequences)\n",
    "print(f\"\\nNLL of oracle-generated sequences: {oracle_nll}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1000 sequences of length 20\n",
      "Sequences shape: torch.Size([1000, 20])\n"
     ]
    }
   ],
   "source": [
    "# Generate some sequences using the Oracle\n",
    "\n",
    "\n",
    "print(f\"Generated {num_samples} sequences of length {sequence_length}\")\n",
    "print(f\"Sequences shape: {oracle_sequences.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NLL of oracle-generated sequences: 8.512005805969238\n"
     ]
    }
   ],
   "source": [
    "oracle_nll = oracle.calculate_nll(oracle_sequences)\n",
    "print(f\"\\nNLL of oracle-generated sequences: {oracle_nll}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL of random sequences: 63.603736877441406\n",
      "Difference: 55.09173107147217\n"
     ]
    }
   ],
   "source": [
    "random_sequences = test_case.generate(num_samples)\n",
    "random_nll = test_case.calculate_nll(oracle_sequences)\n",
    "#print(f\"NLL of random sequences: {random_nll}\")\n",
    "#print(f\"Difference: {random_nll - oracle_nll}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601,\n",
       "         1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601],\n",
       "        [1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601,\n",
       "         1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601],\n",
       "        [1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601,\n",
       "         1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601],\n",
       "        [1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601,\n",
       "         1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601],\n",
       "        [1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601,\n",
       "         1601, 1601, 1601, 1601, 1601, 1601, 1601, 1601]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sequences[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def analyze_tensorflow_dict_params(pickle_path):\n",
    "    \"\"\"\n",
    "    Load and analyze the TensorFlow parameters from a pickle file when stored as a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        pickle_path: Path to the pickle file containing TensorFlow parameters\n",
    "        \n",
    "    Returns:\n",
    "        A detailed analysis of the parameters\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # For Python 3 compatibility\n",
    "        with open(pickle_path, 'rb') as f:\n",
    "            try:\n",
    "                params = pickle.load(f)\n",
    "            except UnicodeDecodeError:\n",
    "                # If fails, try with encoding specification (for Python 3)\n",
    "                f.seek(0)\n",
    "                params = pickle.load(f, encoding='latin1')\n",
    "    except Exception as e:\n",
    "        return f\"Error loading pickle file: {str(e)}\"\n",
    "    \n",
    "    if not isinstance(params, dict):\n",
    "        return f\"Unexpected format: params is not a dict, but {type(params)}\"\n",
    "    \n",
    "    analysis = []\n",
    "    analysis.append(f\"Found {len(params)} parameter entries in dictionary\")\n",
    "    \n",
    "    # Print all keys\n",
    "    analysis.append(\"\\nDictionary keys:\")\n",
    "    for key in params.keys():\n",
    "        analysis.append(f\"- {key}\")\n",
    "    \n",
    "    # Detailed analysis of each parameter\n",
    "    analysis.append(\"\\nDetailed parameter analysis:\")\n",
    "    for key, value in params.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            analysis.append(f\"{key}: Shape {value.shape}, dtype {value.dtype}, min {value.min():.6f}, max {value.max():.6f}, mean {value.mean():.6f}\")\n",
    "        else:\n",
    "            analysis.append(f\"{key}: Not a numpy array, but {type(value)}\")\n",
    "    \n",
    "    return \"\\n\".join(analysis)\n",
    "\n",
    "# Usage example:\n",
    "# analysis = analyze_tensorflow_dict_params('save/target_params.pkl')\n",
    "# print(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 parameter entries in dictionary\n",
      "\n",
      "Dictionary keys:\n",
      "- emb\n",
      "- lstm\n",
      "- out_w\n",
      "- out_b\n",
      "\n",
      "Detailed parameter analysis:\n",
      "emb: Not a numpy array, but <class 'torch.Tensor'>\n",
      "lstm: Not a numpy array, but <class 'dict'>\n",
      "out_w: Not a numpy array, but <class 'torch.Tensor'>\n",
      "out_b: Not a numpy array, but <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "#Usage example:\n",
    "analysis = analyze_tensorflow_dict_params('save/target_params.pkl')\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected format: params is not a dict, but <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#Usage example:\n",
    "analysis = analyze_tensorflow_dict_params('save/target_params_py3.pkl')\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LSTM dictionary contents:\\nweight_ih_l0: Shape torch.Size([128, 32]), dtype torch.float32, min -0.176717, max 0.176691, mean -0.003182\\nweight_hh_l0: Shape torch.Size([128, 32]), dtype torch.float32, min -0.176714, max 0.176738, mean 0.000642\\nbias_ih_l0: Shape torch.Size([128]), dtype torch.float32, min -0.167118, max 0.173759, mean 0.007541\\nbias_hh_l0: Shape torch.Size([128]), dtype torch.float32, min -0.176697, max 0.173152, mean -0.003580'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_lstm_dict(pickle_path):\n",
    "    \"\"\"Analyze the LSTM dictionary in the params\"\"\"\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "    \n",
    "    lstm_dict = params['lstm']\n",
    "    analysis = [\"LSTM dictionary contents:\"]\n",
    "    \n",
    "    for key, value in lstm_dict.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            analysis.append(f\"{key}: Shape {value.shape}, dtype {value.dtype}, min {value.min().item():.6f}, max {value.max().item():.6f}, mean {value.mean().item():.6f}\")\n",
    "        else:\n",
    "            analysis.append(f\"{key}: Not a tensor, but {type(value)}\")\n",
    "    \n",
    "    return \"\\n\".join(analysis)\n",
    "\n",
    "analyze_lstm_dict('save/target_params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Found 15 parameter arrays in list\\nParam 0: Shape (5000, 32), dtype float32, min -4.714428, max 4.362963, mean 0.004206\\nParam 1: Shape (32, 32), dtype float32, min -2.987998, max 3.181021, mean -0.013970\\nParam 2: Shape (32, 32), dtype float32, min -3.022867, max 3.097541, mean 0.039178\\nParam 3: Shape (32,), dtype float32, min -1.939656, max 1.762500, mean 0.152899\\nParam 4: Shape (32, 32), dtype float32, min -3.078522, max 3.077451, mean 0.002182\\nParam 5: Shape (32, 32), dtype float32, min -3.510646, max 2.722268, mean 0.000065\\nParam 6: Shape (32,), dtype float32, min -1.987712, max 1.900762, mean -0.122108\\nParam 7: Shape (32, 32), dtype float32, min -2.970855, max 3.361905, mean 0.014724\\nParam 8: Shape (32, 32), dtype float32, min -3.284508, max 3.296018, mean 0.037364\\nParam 9: Shape (32,), dtype float32, min -1.274701, max 2.060413, mean 0.463960\\nParam 10: Shape (32, 32), dtype float32, min -3.346318, max 2.961451, mean -0.034858\\nParam 11: Shape (32, 32), dtype float32, min -3.358287, max 3.043322, mean 0.032647\\nParam 12: Shape (32,), dtype float32, min -1.789718, max 1.853817, mean -0.108312\\nParam 13: Shape (32, 5000), dtype float32, min -4.433117, max 4.956769, mean -0.000446\\nParam 14: Shape (5000,), dtype float32, min -3.570815, max 3.452207, mean -0.005784'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_tensorflow_list_params(pickle_path):\n",
    "    \"\"\"Analyze parameters stored as a list\"\"\"\n",
    "    try:\n",
    "        with open(pickle_path, 'rb') as f:\n",
    "            try:\n",
    "                params = pickle.load(f)\n",
    "            except UnicodeDecodeError:\n",
    "                f.seek(0)\n",
    "                params = pickle.load(f, encoding='latin1')\n",
    "    except Exception as e:\n",
    "        return f\"Error loading pickle file: {str(e)}\"\n",
    "    \n",
    "    analysis = [f\"Found {len(params)} parameter arrays in list\"]\n",
    "    \n",
    "    for i, param in enumerate(params):\n",
    "        if isinstance(param, np.ndarray):\n",
    "            analysis.append(f\"Param {i}: Shape {param.shape}, dtype {param.dtype}, min {param.min():.6f}, max {param.max():.6f}, mean {param.mean():.6f}\")\n",
    "        elif isinstance(param, torch.Tensor):\n",
    "            analysis.append(f\"Param {i}: Tensor Shape {param.shape}, dtype {param.dtype}, min {param.min().item():.6f}, max {param.max().item():.6f}, mean {param.mean().item():.6f}\")\n",
    "        else:\n",
    "            analysis.append(f\"Param {i}: Not a numpy array or tensor, but {type(param)}\")\n",
    "    \n",
    "    return \"\\n\".join(analysis)\n",
    "\n",
    "analyze_tensorflow_list_params('save/target_params_py3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
